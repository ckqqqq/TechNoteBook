英文写作

60个词太长

转换为列表的形式

![image-20220616093453216](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616093453216.png)

、![image-20220421101124637](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220421101124637.png)

强调

中国学生在英文写作中的问题

![image-20220616094704130](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616094704130.png)

上海纽约大学的一个教授讲的

![image-20220616093559143](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616093559143.png)

This paper



![image-20220616093640021](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616093640021.png)

which和that需要指代明确

驶入没有逗号，容易被人误认为形容后面那个词

![image-20220616093802894](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616093802894.png)

这个词应该有强烈的对比意味

![image-20220616093911723](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616093911723.png)



![image-20220616093947660](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616093947660.png)

错误：滥用

无意义的

![image-20220616094002792](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616094002792.png)

In this paper 

in this study



![image-20220616094022051](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616094022051.png)

in this study

![image-20220616094126509](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616094126509.png)



![image-20220616094157589](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616094157589.png)

避免使用阿拉伯数字，（真的高傲！），阿拉伯数字小于等于10的话，尽量使用英文数字

![image-20220616094211802](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616094211802.png)

greater than

![image-20220616094301910](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616094301910.png)

用在末尾表示列表没有结束，同时使用冗余

![image-20220616094336833](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616094336833.png)

如果表达完整的话，用下面的那个比较好

![image-20220616094432928](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616094432928.png)

缩写尽量不要写在句子的开头，不要用in 需要as

![image-20220616094512113](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616094512113.png)

如果要表示国界使用China

![image-20220616094624162](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616094624162.png)

英文引用后面加空格



比较的时候

不能说这个系统好于那个指标，就是比较的时候要说

这个系统的这个指标好于那个指标



美式英语和英式英语

格式会有latex模板

国外的一个教授经常收到垃圾邮件，所以写了这篇文章。格式

![image-20220616094851368](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616094851368.png)







## 实验室的论文

## 实验室重要的网址：论文报告/组会顺序/要读的论文

https://docs.qq.com/sheet/DSWhFVGZYRExzZGtZ?tab=BB08J2

## 实验室重要的：周记/PPT/文档上传

10.112.243.253

[MM-Wiki - Login](http://10.112.243.253:8081/author/index)



每个人汇报后在这里说汇报了哪些文章ppt可以上传

![image-20220526133956742](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220526133956742.png)

## 情报收集工作

## 调研清华实验室工作 综合 colab









## 清华实验室公开资源

|                                                | 简介                                | 论文/代码                                                    | 其他                                                         |
| ---------------------------------------------- | ----------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| CDial-GPT 2020                                 | 模型：中文GPT                       | 论文/代码：https://arxiv.org/abs/2008.03946                                   https://github.com/thu-coai/CDial-GPT 预训练模型https://huggingface.co/thu-coai/CDial-GPT_LCCC-large | 有评测框架，文档太牛了好评                                   |
| MMChat 2022                                    | 模型：多模态对话系统                | 论文/代码:https://github.com/silverriver/MMChat    https://arxiv.org/abs/2108.07154 | ![image-20220505090640326](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220505090640326.png) |
| LCCC(Large-scale Cleaned Chinese Conversation) | 清洗脏话/颜文字的大型中文预训练框架 | 网盘：https://drive.google.com/file/d/1hhxXqEqmXegf8Ca0MVQyVshlEi7hsjPi/view?usp=sharing 介绍https://github.com/thu-coai/CDial-GPT | 对话轮次为百万级别，集合微博，百度文库的训练集合             |
| SentiLARE：用于情感分析的语言表示模型 2020     | 情感分析                            | 论文链接：https://www.aclweb.org/anthology/2020.emnlp-main.567/<br/><br/>代码、预训练模型、数据链接：https://github.com/thu-coai/SentiLARE                                        模型介绍：http://coai.cs.tsinghua.edu.cn/tools/4 | 引入词性和情感级性后适用于情感分析任务的语言表示模型         |
|                                                |                                     |                                                              |                                                              |
|                                                |                                     |                                                              |                                                              |
|                                                |                                     |                                                              |                                                              |
|                                                |                                     |                                                              |                                                              |
|                                                |                                     |                                                              |                                                              |



## 其他开源数据  对话生成

|                                              | 简介                               | 代码/论文/网盘                                               | 其他                           |
| -------------------------------------------- | ---------------------------------- | ------------------------------------------------------------ | ------------------------------ |
| STC 数据集  权威                             | 公开数据集比较有名，论文中出现较多 | train/test https://drive.google.com/file/d/1jsTyvOz0y_6UIAkaibvvxf6bw0REqAlO/view?usp=sharing test https://drive.google.com/file/d/15jEriASrMX4r1zShY-pvDPLt-gOF4Wbg/view?usp=sharing | 大家都在用，好像是2017的       |
| CMDA （不权威）                              | 中文医疗数据集                     | https://github.com/Toyhom/Chinese-medical-dialogue-data      | 逛github看到的，但是感觉比较拉 |
| Cornell Movie Dialogs 权威（下载网址不确定） | 康奈尔的电影对话                   | https://download.csdn.net/download/u014736221/10596024?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-download-2%7Edefault%7ECTRLIST%7EPaid-1.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant_t0.none-task-download-2%7Edefault%7ECTRLIST%7EPaid-1.pc_relevant_default&utm_relevant_index=1 | 2M影评数据集，究极老的数据集   |
|                                              |                                    |                                                              |                                |
| 中文词向量                                   | （不威）                           | 腾讯10G（本地）、https://github.com/fighting41love/funNLP、gia |                                |
| 中文聊天语料库 不                            | （权威）                           | https://github.com/codemayq/chaotbot_corpus_Chinese          | 豆瓣，青云语料，电视剧对白     |
| 中文问答数据集                               | （不权威）                         | https://pan.baidu.com/s/1QUsKcFWZ7Tg1dk_AbldZ1A              | 没看                           |
| 对联数据23333                                |                                    | https://github.com/wb14123/couplet-dataset                   |                                |
| 青云语料库                                   | 权威                               | 但是没有                                                     |                                |
| 大规模医疗对话集                             |                                    | https://github.com/yaleimeng/Final_word_Similarity           | 110万条医学咨询                |
| 根据rasa对话的代码                           | rasa速速参考                       | https://github.com/GaoQ1/rasa_chatbot_cn                     | 下周                           |

竟然可以在外包平台上进行人工评测来验证机器生成的对话，牛啊

## 辅助任务：知识图谱：情感分析：非对话的中文语料

|                                          | 简介       | 资源                                                    | 其他 |
| ---------------------------------------- | ---------- | ------------------------------------------------------- | ---- |
| 中文事件抽取                             | 事件抽取   | https://github.com/liuhuanyong/ComplexEventExtraction   |      |
|                                          |            |                                                         |      |
| 清华的跨语言知识图谱                     | 知识图谱   | https://xlore.org/download.html                         |      |
| 微信公众号爬虫的结果                     | 不如自己爬 | https://github.com/nonamestreet/weixin_public_corpus    |      |
| 苏大的句法标注                           |            | http://hlt.suda.edu.cn/index.php/Nlpcc-2019-shared-task |      |
| 瑞金医院知识图谱                         |            | https://github.com/geekinglcq/CDCS                      |      |
| 2015年至19年的所有kaggle上的知识图谱数据 | 权威       | https://github.com/geekinglcq/CDCS                      |      |
| 中文知识图谱的资源汇总                   |            | https://github.com/husthuke/awesome-knowledge-graph     |      |
| 中文知识图谱汇总                         |            | https://github.com/husthuke/awesome-knowledge-graph     |      |
| 中文词语相似度                           |            | https://github.com/yaleimeng/Final_word_Similarity      |      |

|                                |                                                              | 资源                                                         |
| ------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 知识图谱                       | 小综述                                                       | https://developer.aliyun.com/article/761513?utm_content=g_1000124809 |
| 132知识图谱数据集              | 常识、城市、金融、农业、地理、气象、社交、物联网、医疗、娱乐、生活、商业、出行、科教啊啊啊太多了 | http://openkg.cn/dataset                                     |
|                                |                                                              |                                                              |
| 维基百科，百度百科             |                                                              | https://gist.github.com/thomwolf/13ca2b2b172b2d17ac66685aa2eeba62 |
| 大规模中文知识图谱             | 1.3亿实体                                                    | https://github.com/ownthink/KnowledgeGraphData               |
|                                | 序列标注工具                                                 | http://brat.nlplab.org/index.html                            |
| 人民日报语料库                 |                                                              | https://github.com/howl-anderson/tools_for_corpus_of_people_daily |
| 句子相似度判定模型             |                                                              | https://github.com/liuhuanyong/SiameseSentenceSimilarity     |
| 基于医药知识图谱的智能问答系统 |                                                              | https://github.com/YeYzheng/KGQA-Based-On-medicine           |

NePF方向的

https://github.com/yenchenlin/awesome-NeRF

## 瑞士军刀:学习资料

|                        | 解释             | 资源                                                  |
| ---------------------- | ---------------- | ----------------------------------------------------- |
| jieba                  | 不多bb           |                                                       |
| 复旦NLP                | 复旦nlp集        | https://github.com/fighting41love/funNLP              |
|                        |                  | https://github.com/nl8590687/ASRT_SpeechRecognition   |
| 命名实体               | 之前有搜集了一堆 |                                                       |
| 三元组搜取             |                  | https://github.com/liuhuanyong/EventTriplesExtraction |
| 啊啊太多了用的时候再找 |                  |                                                       |
|                        |                  | https://github.com/huyingxi/Synonyms                  |
| 真得供起来烧柱香       |                  | https://github.com/fighting41love/funNLP              |
| 清华2018年的报告       | ybb              | https://static.aminer.cn/misc/article/nlp.pdf         |
| 自然语言的基本模型     |                  | https://github.com/lpty/nlp_base                      |

学习

https://github.com/npubird/KnowledgeGraphCourse



 **ASR 语音数据集 + 基于深度学习的中文语音识别系统：**  [github](https://github.com/nl8590687/ASRT_SpeechRecognition)

- Data Sets 数据集

  - **清华大学THCHS30中文语音数据集**

    data_thchs30.tgz [OpenSLR国内镜像](http://cn-mirror.openslr.org/resources/18/data_thchs30.tgz) [OpenSLR国外镜像](http://www.openslr.org/resources/18/data_thchs30.tgz)

    test-noise.tgz [OpenSLR国内镜像](http://cn-mirror.openslr.org/resources/18/test-noise.tgz) [OpenSLR国外镜像](http://www.openslr.org/resources/18/test-noise.tgz)

    resource.tgz [OpenSLR国内镜像](http://cn-mirror.openslr.org/resources/18/resource.tgz) [OpenSLR国外镜像](http://www.openslr.org/resources/18/resource.tgz)

  - **Free ST Chinese Mandarin Corpus**

    ST-CMDS-20170001_1-OS.tar.gz [OpenSLR国内镜像](http://cn-mirror.openslr.org/resources/38/ST-CMDS-20170001_1-OS.tar.gz) [OpenSLR国外镜像](http://www.openslr.org/resources/38/ST-CMDS-20170001_1-OS.tar.gz)

  - **AIShell-1 开源版数据集**

    data_aishell.tgz [OpenSLR国内镜像](http://cn-mirror.openslr.org/resources/33/data_aishell.tgz) [OpenSLR国外镜像](http://www.openslr.org/resources/33/data_aishell.tgz)

  注：数据集解压方法

  ```
  $ tar xzf data_aishell.tgz
  $ cd data_aishell/wav
  $ for tar in *.tar.gz;  do tar xvf $tar; done
  ```

  - **Primewords Chinese Corpus Set 1**

    primewords_md_2018_set1.tar.gz [OpenSLR国内镜像](http://cn-mirror.openslr.org/resources/47/primewords_md_2018_set1.tar.gz) [OpenSLR国外镜像](http://www.openslr.org/resources/47/primewords_md_2018_set1.tar.gz)



## 调研 GPT-3 & open-AI

open AI 申请

跑GPT-2 服务器上

看GPT-3 的论文（然而没有）bert

Rasa

我还在搞轨迹预测的工作，实验遇到了一点小问题



![image-20220428104803603](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220428104803603.png)



Rasa是一个基于多轮对话的框架，其中包含两个模块Rasa core与Rasa nlu。

**Rasa nlu**是用来理解语义的，包括意图识别，实体识别，它会把用户的输入转换为结构化的数据，例如在下图的例子中，nlu会识别出用户打算发一封邮件（意图），邮箱地址amy@example.com（实体）。Rasa Core是一个对话管理的平台，它的工作是决定接下来机器该返回什么内容给用户，这里给用户返回了Should we make that your primary email?

Tokenize->Featurize->NER Extract->Intent Classify  大概流程吧

![image-20220616121600863](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220616121600863.png)

![image-20220428113605250](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220428113605250.png)

**Rasa Core**是一个对话管理的平台，它的工作是决定接下来机器该返回什么内容给用户，这里给用户返回了Should we make that your primary email?

![image-20220428111512502](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220428111512502.png)

![image-20220428113257560](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220428113257560.png)

### NLU

NLU的任务是解析消息，它能把自然语言解释成我们需要的结构化的数据，我们继续完善下去。

NLU的任务是解析消息，它能把自然语言解释成我们需要的结构化的数据，我们继续完善下去。

可以设置多个机器人，可以面向不同领域

![image-20220428110735512](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220428110735512.png)

![image-20220428111702800](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220428111702800.png)

1. 支持命令行启动训练和推理
2. 支持http调用，并满足统一的接口规范
3. 支持训练数据和模型远程存储

## RASA信息流向

1. 消息传入后，被Interpreter接收
2. interpreter接收消息后，将消息转换成字典（tokenizer），并转化成特征（featurizer），提取命名实体（Extractors），识别意图（Classifier）。这部分叫做自然语言理解（NLU）。interpreter将输出包括实体，意图，以及对话的特征一起传给Tracker。
3. Tracker用来追踪记录对话状态的对象，Tracker的当前状态（特征，意图，实体）以及历史状态信息一并传给Policy。
4. Policy将当前状态以及历史状态一并特征化，并传入预测模型（Policy），预测模型预测出下一个动作（Action）。
5. Action完成实际动作，并将动作结果通知到tracker，成为历史状态。
6. Action将结果返回给用户。

## 扩展：

意图分类器

实体提取器

### Rasa大佬连接     https://zhuanlan.zhihu.com/p/331806270

Rasa为建立高效，灵活，专有的上下文对话机器人提供了必要的基础架构和工具。使用Rasa，任何人员都可以通过文本编辑器配置配置文件，就可以得到一个非常不错的对话机器人。

正因为对话机器人有如此广泛的应用，技术应用也层出不穷。如百度开源的基于检索式机器人的框架AnyQ；Google开源的基于生成式对话系统DeepQA；Facebook开源的基于阅读理解的系统DrQA；北京大学知识库问答系统gAnswer。但这些技术都是为了完成对话系统中的一个任务，或者说为了机器人的一个能力而开发的技术，而现有的对话系统中多是各种技术的混合，例如一个对话系统，闲聊部分可能用到DeepQA一类的NLG技术，关于知识推理部分可能用到KBQA的部分，关于FAQ的回答可能用到AnyQ或者DRQA。如何将这些技术应用到一个系统中，还是对应用开发人员的一个考验。

幸运的是，近些年来，很多厂商都开源了自己的问答系统，整个系统是开包即用，例如Facebook开源的Blender系统，他具有个性人物聊天的功能，可以知识问答，是有史以来最大的开放域（Open-Domain）聊天机器人。还有Uber开源的Plato系统，也都具有比较完整的功能。但要说从**框架完整性，可扩展性，易用性**等各方面，RASA当仁不让是当前最全面的系统之一。下面我们详细介绍下RASA系统。

#### 1、Stories

stories可以理解为对话的场景流程，我们需要告诉机器我们的多轮场景是怎么样的，例如，在下文的例子中，我们希望的流程是这样的：用户问好 -> 机器问用户今天过得怎么样 -> 用户反馈情绪 -> 机器根据不同的情绪进行回复，这里其实包含两个流程，一个正面情绪的流程与一个负面情绪的流程，因此，我们也需要编写两个story，接下来我们看下怎么编写story。
符号 	说明

![image-20220428111155378](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220428111155378.png)

story 标题

* 	意图
- 动作

  2、Domain

  domain可以理解为机器的知识库，其中定义了意图，动作，以及对应动作所反馈的内容。


## GPT-3

key - 的申请

#### 深度学习-Pre-training-fine-toning

简单介绍GPT-3

每个Transformer单元相当于一层的RNN层，接收一整个句子所有词作为输入，然后为句子中的每个词都做出一个输出。但是与RNN不同的是，Transformer能够同时处理句子中的所有词，并且任意两个词之间的操作距离都是1，这么一来就很好地解决了上面提到的RNN的效率问题和距离问题。

每个Transformer单元都有两个最重要的子层，分别是Self-Attention层与Feed  Forward层，后面会对这两个层的详细结构做介绍。文章使用Transformer搭建了一个类似Seq2Seq的语言翻译模型，并为Encoder与Decoder设计了两种不同的Transformer结构。

GPT-3和bert 的差别

| GPT-3            | BERT                                   |
| ---------------- | -------------------------------------- |
| Transfomer编码器 | 解码器                                 |
| 单向             | 双向                                   |
|                  | mask                                   |
|                  | 都是transformer的+pretrain+fine tuning |
| BPE(字节码)      |                                        |

### 预训练(pre-training/trained)：

你需要搭建一个网络来完成一个特定的图像分类的任务。首先，你需要随机初始化参数，然后开始训练网络，不断调整直到网络的损失越来越小。在训练的过程中，一开始初始化的参数会不断变化。当你觉得结果很满意的时候，就可以将训练模型的参数保存下来，以便训练好的模型可以在下次执行类似任务时获得较好的结果。这个过程就是pre-training。

之后，你又接收到一个类似的图像分类的任务。这个时候，你可以直接使用之前保存下来的模型的参数来作为这一任务的初始化参数，然后在训练的过程中，依据结果不断进行一些修改。这时候，你使用的就是一个pre-trained模型，而过程就是fine-tuning。

所以，预训练就是指预先训练的一个模型或者指预先训练模型的过程；微调 就是指将预训练过的模型作用于自己的数据集，并参数适应自己数据集的过程。

### 微调的作用

在CNN领域中。很少人自己从头训练一个CNN网络。主要原因上自己很小的概率会拥有足够大的数据集，从头训练，很容易造成过拟合。

所以，一般的操作都是在一个大型的数据集上训练一个模型，然后使用该模型作为类似任务的初始化或者特征提取器。比如VGG，Inception等模型都提供了自己的训练参数，以便人们可以拿来微调。这样既节省了时间和计算资源，又能很快的达到较好的效果。 

大家好，我是19级软件工程专业的陈可淇，有过半年左右轨迹预测方向的科研经历，计划在实验室实习的方向是口语对话系统，请大家多多指教~~

我这周还是在做轨迹预测方向的事情，那边目前还是顺利的，ddl是5月17号（CIKM） 应该可以赶上，然后17号之后我可以花大多数时间在这边的工作了。

不中就转期刊

口语对话系统方向的话，我就到github上找了一些主流模型，看了一下源码，还没部署。

GAN 论文

类型、

![image-20220428122852193](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220428122852193.png)

## 爬虫笔记|POI爬取|BingMapblog

POI基本类型

[POI Entity Types - Bing Maps | Microsoft Docs](https://docs.microsoft.com/en-us/bingmaps/spatial-data-services/public-data-sources/poi-entity-types)

[Get Data Source Information - Bing Maps | Microsoft Docs](https://docs.microsoft.com/en-us/bingmaps/spatial-data-services/data-source-management-api/get-data-source-information)

[Account details - Bing Maps Dev Center (bingmapsportal.com)](https://www.bingmapsportal.com/Account)

https://docs.microsoft.com/en-us/bingmaps/spatial-data-services/public-data-sources/pointsofinterest

string DataSourceID = "20181f26d9e94c81acdf9496133d4f23";

我的accountid

```bash
1960411
```

我的key

```bash
AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
```



[Get Data Source Information - Bing Maps | Microsoft Docs](https://docs.microsoft.com/en-us/bingmaps/spatial-data-services/data-source-management-api/get-data-source-information)

获得datasource ID 的方式

**Example**: $format=json

```bash
http://spatial.virtualearth.net/REST/v1/data?$format=formatQueryOption&key=anyKeyFromTheBingMapsAccount

http://spatial.virtualearth.net/REST/v1/data?$format=json&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
```

![image-20220414204323416](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220414204323416.png)

```bash
http://spatial.virtualearth.net/REST/v1/data?$format=atom&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
```

![image-20220414204432260](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220414204432260.png)

atom="http://www.w3.org/2005/Atom" xmlns:bsi="http://schemas.microsoft.com/bing/spatial/2010/11/odata"

![image-20220414205748922](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220414205748922.png)

![image-20220414203710136](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220414203710136.png)

https://docs.microsoft.com/en-us/bingmaps/spatial-data-services/public-data-sources/pointsofinterest

$符号后面的含义

https://docs.microsoft.com/en-us/bingmaps/spatial-data-services/query-api/query-options

#### 获得poi的方式





| Entity Type Name                                             | Entity Type ID |
| :----------------------------------------------------------- | :------------- |
| Agricultural Structure                                       | 6              |
| Airport                                                      | 4581           |
| Airport Runway                                               | 8              |
| Airport Terminal                                             | 237            |
| Amusement Park                                               | 7996           |
| Apparel Store (Clothing Store)                               | 9537           |
| ATM                                                          | 3578           |
| Auto Dealership                                              | 5511           |
| Auto Service & Maintenance                                   | 7538           |
| Bank                                                         | 6000           |
| Bookstore                                                    | 9995           |
| Border Post (Border Crossing)                                | 9999           |
| Bowling Alley/Centre                                         | 7933           |
| Bridge                                                       | 19             |
| Bus Station                                                  | 4170           |
| Business Facility (Administrative/Office Building, Business Center and Factory) | 5000           |
| Camp (Campground)                                            | 9517           |
| Casino                                                       | 7985           |
| Cemetery                                                     | 9591           |
| Cinema                                                       | 7832           |
| City Hall                                                    | 9121           |
| Coffee Shop                                                  | 9996           |
| Community Center (Civic/Community Centre)                    | 7994           |
| Consumer Electronics Store                                   | 9987           |
| Convenience Store                                            | 9535           |
| Convention Center (Convention/Exhibition Centre)             | 7990           |
| Court House                                                  | 9211           |
| Currency Exchange                                            | 220            |
| Dam                                                          | 45             |
| Department Store                                             | 9545           |
| Educational Structure                                        | 54             |
| Embassy                                                      | 9993           |
| Fast Food                                                    | 275            |
| Ferry Terminal                                               | 4482           |
| Financial Structure                                          | 193            |
| Fire Station                                                 | 270            |
| Fish Hatchery                                                | 59             |
| Gas Station (Petrol/Gasoline Station)                        | 5540           |
| Golf Course                                                  | 7992           |
| Government Structure (Government Office)                     | 9525           |
| Grocery Store                                                | 5400           |
| Heliport                                                     | 73             |
| Higher Education Facility (Higher Education)                 | 8200           |
| Historical Monument (Battlefield, Fort and Historical Site)  | 5999           |
| Home Improvement (Hardware and Home Furnishing Store)        | 9986           |
| Hospital                                                     | 8060           |
| Hotel                                                        | 7011           |
| Ice Skating Rink                                             | 7998           |
| Industrial Zone                                              | 9991           |
| Information Center (Tourist Information)                     | 7389           |
| Junction                                                     | 87             |
| Library                                                      | 8231           |
| Lighthouse                                                   | 94             |
| Marina                                                       | 4493           |
| Medical Service (Doctor Office and Medical Structure)        | 9583           |
| Military Base                                                | 9715           |
| Motorcycle Dealership                                        | 5571           |
| Multi Modal Station                                          | 238            |
| Museum                                                       | 8410           |
| Neighborhood (Hamlet)                                        | 9998           |
| Nightlife (Bar, Discotheque, Jazz Club, Karaoke Club and Private Club) | 5813           |
| Observation Point                                            | 114            |
| Office Supply Store (Office Supply & Services Store)         | 9988           |
| Other Accommodation (Bed and Breakfast, Cabin, Hostel, Motel and Resort) | 7013           |
| Park (Park/Recreation Area)                                  | 7947           |
| Park & Ride                                                  | 7522           |
| Parking Garage/House                                         | 7521           |
| Performing Arts (Comedy Club and Theater)                    | 7929           |
| Personal Care Facility                                       | 303            |
| Pharmacy                                                     | 9565           |
| Place of Worship (Church, Mission, Mosque, Temple and Religious Structure) | 9992           |
| Police Station                                               | 9221           |
| Populated Place                                              | 4444           |
| Port                                                         | 280            |
| Post Office                                                  | 9530           |
| Prison                                                       | 137            |
| Railway Station                                              | 4013           |
| Railway Station Entrance                                     | 273            |
| Recreational Structure                                       | 142            |
| Rental Car Agency                                            | 7510           |
| Residential Structure (Residential Area/Building)            | 9590           |
| Rest Area                                                    | 7897           |
| Restaurant                                                   | 5800           |
| Ruin                                                         | 153            |
| School                                                       | 8211           |
| Scientific Research Base                                     | 156            |
| Shopping (Market and Shopping Center)                        | 6512           |
| Ski Area (Ski Resort)                                        | 7012           |
| Specialty Store (Hobby Store, Pet Store and Warehouse Club)  | 9567           |
| Sporting Goods Store                                         | 9568           |
| Sports Complex (Playing Field and Race Track)                | 7940           |
| Stadium (Sports Centre)                                      | 7997           |
| Store                                                        | 259            |
| Tollgate                                                     | 283            |
| Transportation Service (Metro Station, Railway and Transportation Structure) | 7999           |
| Trailhead                                                    | 236            |
| Tramway                                                      | 262            |
| Transportation Service (Metro Station, Railway and Transportation Structure) | 9593           |
| Truck Dealership                                             | 9719           |
| Truck Stop (Truck Stop/Plaza)                                | 9522           |
| Tunnel                                                       | 177            |
| Vehicle Organization Office (Automobile Club)                | 8699           |
| Veterinarian                                                 | 304            |
| Weigh Station                                                | 9710           |
| Winery                                                       | 2084           |
| Zoo (Animal Park)                                            | 9718           |

```bash

http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=nearby(40.83274904439099,-74.3163299560546935,5)&$filter=EntityTypeID%20eq%20'6000'&$select=EntityID,DisplayName,Latitude,Longitude,__Distance&$top=3&key=anyBingMapsKey

http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=nearby(40.83274904439099,-74.3163299560546935,5)&$filter=EntityTypeID%20eq%20'6000'&$select=EntityID,DisplayName,Latitude,Longitude,__Distance&$top=3&key=anyBingMapsKey
#成功
http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=nearby(47.610005,-122.185992,5)&$filter=EntityTypeID%20eq%20'6000'&$select=987654321123456789,Contoso Cafe,47.610005,-122.185992,5&$top=3&key= AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
#成功
http://spatial.virtualearth.net/REST/v1/data/20181f26d9e94c81acdf9496133d4f23/FourthCoffeeSample/FourthCoffeeShops?spatialFilter=bbox(47.61247675940658,-122.3237670214032,47.68239156080077,-122.27996173131822)&$format=json&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv

http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=bbox(-8.6390627,41.0133802,-8.6330627,41.0193802)&$format=json&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv

http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=bbox(40.83274904439099,-74.3163299560546935,40.89274904439099,-74.2663299560546935)&$format=json&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
#葡萄牙的 ok的
http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=bbox(41.0133802,-8.6390627,41.4693802,-8.0330627)&$format=json&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
#葡萄牙再试试
http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=bbox(41.0133802,-8.6390627,41.4693802,-8.0330627)&&$format=json&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
#尝试typeID

http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=bbox(41.0133802,-8.6390627,41.4693802,-8.0330627)&$filter=EntityTypeID%20eq%20'6000'&$format=json&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
#尝试最大返回数量
#bingmap
http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=bbox(41.0133802,-8.6390627,41.4693802,-8.0330627)&$filter=EntityTypeID%20eq%20'3578'&$top=30&$inlinecount=allpages&$format=json&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
#一个小区域
http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=bbox(41.0633802,-8.6390627,41.0693802,-8.6380627)&$filter=EntityTypeID%20eq%20'3578'&$top=30&$inlinecount=allpages&$format=json&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
#实际操作
#查询 ATM
http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=bbox(41.0133802,-8.6390627,41.4693802,-8.0330627)&$filter=EntityTypeID%20eq%20'3578'&$top=3&$inlinecount=allpages&$format=json&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv

http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=bbox(41.0133802,-8.6390627,41.4693802,-8.0330627)&$filter=EntityTypeID%20eq%20'6'&$top=3&$inlinecount=allpages&$format=json&key=ziu1YyE2u18ghBoVIQd0~kWxeBQC0Baa5TZ4L8FzDEg~AvXvRAO5no9FUbe-oIx-lxo03d2fNUuV90eWCG1pEWmmK3MB9V5mLSej32THZj2k




http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=bbox(41.0133802,-8.6390627,41.4693802,-8.6330627)&$filter=EntityTypeID%20eq%20'6'&$top=3&$inlinecount=allpages&$format=json&key=ziu1YyE2u18ghBoVIQd0~kWxeBQC0Baa5TZ4L8FzDEg~AvXvRAO5no9FUbe-oIx-lxo03d2fNUuV90eWCG1pEWmmK3MB9V5mLSej32THZj2k
#卡住的
-7.8980627,41.1903802
41.1873802,-7.9010627
41.1933802,-7.8950627
http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=bbox(41.1873802,-7.9010627,41.1933802,-7.8950627)&$filter=EntityTypeID%20eq%20'4170'&$top=3&$inlinecount=allpages&$format=json&key=ziu1YyE2u18ghBoVIQd0~kWxeBQC0Baa5TZ4L8FzDEg~AvXvRAO5no9FUbe-oIx-lxo03d2fNUuV90eWCG1pEWmmK3MB9V5mLSej32THZj2k

http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=bbox(41.1873802,-7.9010627,41.1933802,-7.8950627)&$top=3&$inlinecount=allpages&$format=json&key=ziu1YyE2u18ghBoVIQd0~kWxeBQC0Baa5TZ4L8FzDEg~AvXvRAO5no9FUbe-oIx-lxo03d2fNUuV90eWCG1pEWmmK3MB9V5mLSej32THZj2k
http.client.IncompleteRead: IncompleteRead(190 bytes read)
```

![image-20220415201120514](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220415201120514.png)

```python
http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?spatialFilter=bbox(41.0133802,-8.6390627,41.4693802,-8.0330627)&$format=json&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv

http://spatial.virtualearth.net/REST/v1/data/Microsoft/PointsOfInterest?
spatialFilter=bbox(-8.6390627,41.0133802,-8.6330627,41.0193802)&&$format=json&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
```



![image-20220414204209533](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220414204209533.png)





```BASH
http://spatial.virtualearth.net/REST/v1/data/accessId/dataSourceName/entityTypeName?spatialFilter=nearby(latitude,longitude,distance)&queryoption1&queryoption2&queryoptionN&jsonp=jsonCallBackFunction&jsonso=jsonState&isStaging=isStaging&key=queryKey  
0
accessID，
1
string dataSourceName = "FourthCoffeeSample";  
        // Name of entities in the data source
 2
        string dataEntityName = "FourthCoffeeShops";  
      // Unique access ID assigned to your data source by Bing Maps  
http://spatial.virtualearth.net/REST/v1/data/20181f26d9e94c81acdf9496133d4f23/FourthCoffeeSample/FourthCoffeeShops?spatialFilter=bbox(-8.6390627,41.0133802,-8.6330627,41.0193802)&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv



http://spatial.virtualearth.net/REST/v1/data/20181f26d9e94c81acdf9496133d4f23/FourthCoffeeSample/FourthCoffeeShops?spatialFilter=bbox(47.61247675940658,-122.3237670214032,47.68239156080077,-122.27996173131822)&$format=json&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
```



### '命名实体识别笔记

我在北京邮电大学研究重庆人

![image-20220414145015299](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220414145015299.png)



### 轨迹预测

```bash
D:\Research_2021\子诚论文笔记.drawio
cd D:\Research_2021\
```



必要出行具有多层次周期性

非必要出行时，用户对各个POI的兴趣会随着当前时间，距离POI点距离此时段的锚点变化而变化

您好，打扰了。我们是北京邮电大学计算机学院的研究组，我们的研究方向是轨迹预测。为了提升我们模型的实际效果，我们需要用到高德地图海外版获取葡萄牙小城港口城市波尔图的全城poi数据（Portugal-Porto）。如您提供该poi接口，我们将不胜感激，在论文中标明数据来源，并在论文结尾表达致谢。

论文

Trajectory prediction has always been a hot topic in major fields such as social management, geography, transportation and computing.

```html
http://spatial.virtualearth.net/REST/v1/data/accessId/dataSourceName/entityTypeName?spatialFilter=nearby(-8.3840627,41.0043802,3)&queryoption1&queryoption2&queryoptionN&jsonp=jsonCallBackFunction&jsonso=jsonState&isStaging=isStaging&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
```



```bash
http://spatial.virtualearth.net/REST/v1/data/accessId/dataSourceName/entityTypeName?spatialFilter=nearby(beijing,3)&queryoption1&queryoption2&queryoptionN&jsonp=jsonCallBackFunction&jsonso=jsonState&isStaging=isStaging&key=AnCG7cHEP8TN6ZilEXG30miEDjCbt2vjWr4uJ0CuBcFD2TDLwBix6j78Lq8FMQiv
```

写论文

## **abstract**

**当前挑战任务**

二选一Trajectory prediction   is a fundamental task for 用户推荐，路径规划，交通调度（二选一）

Trajectory prediction plays a crucial /vital role in  geography, sociology and computer science and （二选一）

It is a （challenging） task to predict User's location base on Historical trajectory and relevant information。



Unfortunately，trajectory prediction is still challenging because of these reasons: 

1.the complex sequential transition regularities exhibited with time-dependent and high- order nature;

抄的）轨迹预测 由于一下几个原因当前遇到了一下问题（）同一转换+换同义词+多加减一个问题

2) the multi-level periodicity of human mobility; and
3)  3) the heterogeneity and sparsity of the collected trajectory data.

1  （抄的）轨迹预测 由于一下几个原因当前遇到了一下问题（）

2,



（The recent advances in trajectory prediction have been mainly dirven by xxx 和XXX (介绍别人主流模型)、

然鹅他们的模型有这样那样的问题

问题1.

2

踩一捧一 我目前不清楚位置，也不知道加不加）

In this paper,we construct the XXX to describe XXX to tackle these difficulties.

我们首先，然后 最后

我们的模型在kaggle上取得了一定的效果

we evaluate our model at XX dataset and kaggle dataset（放连接）

Our XX achieve new kaggle perfomance of 99%

Code is available at我们的github（需要讨论）







碰瓷 Although XXX can effenciently XXX ,it lack the capability to  

Alternatively XXX can effectively XX

while having 

Based on these observation , we propose XX,which XXX

Different form XX , we can 

Our XX achieve new kaggle perfomance of 

Code is available at

In this paper,we construct the XXX to describe XXX to tackle these difficulties.

We propose the XXX name 

we evaluate our model on (尽量是相关的数据集)吗， 

宇豪论文里面可能会用 The experiment results show that the proposed model out perfoems six baseline

and is more robust to XX

possesses three unique characteristics 1）XXX 2）XXX

We further originally propose a XXX to solve data dimensionality  and data sparsity issues

In particulat ,XXX adopts XXX to predict a more accurate destination location 

## **Introduction** 

XXX is a fundamental task for XXX

On the one hand ,on the other hand 

The XXX have/is driven by XXX

Unfortunately

XXX suffers from difficultu in XXX

To tackle these difficulties.

Hence,

However,

Alternatively,

展示图片

We respectively show XXX 







## 会议评级

[计算机会议排名等级 - Alexander - 博客园 (cnblogs.com)](https://www.cnblogs.com/bnuvincent/p/6809353.html)

## 腾讯文档

[destination predication (qq.com)](https://docs.qq.com/sheet/DZElLdlZtRUJtZ3hI?scene=027a498772f23c44b1ee4b637uwCn1&tab=BB08J2)

## Scihub

[Sci-Hub: removing barriers in the way of science](https://sci-hub.st/)

https://sci-hub.st/

## 序号：读论文的模板

![](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220122150030231.png)

### 相关信息：

**论文标题：An Attention-Based Deep Learning Framework for Trip Destination Prediction of Sharing Bike**

**year：2020**

**Publish :IEEE Transactions**

**Cited:35**

**Code：无**

**Data：无**

### 数据预处理：UserID 纬度 经度 时间戳

### 核心IDEA：

### 精读部分：模型组成

### 精读部分：参考资料与总结



## 序号：2 An Attention-Based Deep Learning Framework for Trip Destination Prediction of Sharing Bike

没数据没代码

### 相关信息：

论文标题：An Attention-Based Deep Learning Framework for Trip Destination Prediction of Sharing Bike

年份：2020

期刊:  IEEE Transaction

引用量: 35

源代码：无

数据：无

### 数据预处理：UserID 纬度 经度 时间戳



### 核心IDEA



### 精读部分：模型组成

简述基于attention的共享单车轨迹预测，无数据集无代码

好处，结构简单 比较直接 突出重点

坏处：典型水论文

启发：单独对比各处的改进，

![image-20220118203557651](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220118203557651.png)

主要结构结构

1 embeddding

start & desti 

输入 k个用户和 n个 potential trip destination

输出 K个用户和h*D的Destination Matrix



![image-20220118201825028](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220118201825028.png)

2 convolutional layer吧（RELU函数）

Aim : extract potential features

找出S个 卷积核分别对应 不同大小的特征提取

![image-20220118203342348](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220118203342348.png)



3 Attention Layer

![image-20220118203707494](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220118203707494.png)



![image-20220118203653355](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220118203653355.png)

输出层

![image-20220118203818308](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220118203818308.png)

### 精读部分：参考资料与总结

## 序号 16: Improving_Destination_Prediction_via_Ensemble_of_Trajectory_Movement_Separation_and_Adaptive_Clustering







略读 **子适应性聚类**可以借鉴一下

一种改进型的DbSCAN

有趣的是他只对end-point 进行聚类

![image-20220118205640942](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220118205640942.png)

![image-20220118205556342](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220118205556342.png)



![image-20220118205754699](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220118205754699.png)

![image-20220118205500181](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220118205500181.png)





## 序号 6：Destination prediction based on partial trajectory data

4星

### 相关信息：

论文标题：Destination prediction based on partial trajectory data

year：Received 14 May 2019, Revised 22 August 2019, Accepted 23 September 2019, Available online 12 April 2020.

期刊: 2020 IEEE Intelligent Vehicles Symposium (IV）

| IEEE-IV | Intelligent Vehicles Conference | B    |
| ------- | ------------------------------- | ---- |
|         |                                 |      |

cited: 7

源代码：没

数据：某一个kaggle比赛的数据，排名第一，然而

https://www.kaggle.com/c/pkdd-15-predict-taxi-service-trajectory-i/data



![image-20220122161424132](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220122161424132.png)

又找到一个与我们相关的比赛

![image-20220122164318115](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220122164318115.png)

有意思的是，他们还提供**有天气数据**

[Frontier Weather: Login (dtn.com)](https://frontierweather.dtn.com/amember/login)

 We   retrieved   the   weather-related   data   for   San   Francisco   from   www. frontierweather.com  and  for  Porto  from  www.meteob

英语学习：

substitute 替代品，名词

sparse 系数

spatial partitioning 空间分区

underlying 基础的

congruent 一致的

Author: Center for Future Media & School of Computer Science and Engineering, University of Electronic Science and Technology of China, China



### 数据预处理：UserID 纬度 经度 时间戳

### 核心IDEA：

![image-20220122191642901](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220122191642901.png)

目标解决数据集稀疏的问题：

|            | advantage      | disadvantage                                                 |
| ---------- | -------------- | ------------------------------------------------------------ |
| 路网映射   | 基于基本的路网 | 大量的路网连接可能加剧了空余空间问题                         |
| 空间分区   | 简单快速       | 没有考虑轨迹的空间分布。数据点分布不平衡-》预测准确性的损失。 |
| 前人方法一 |                |                                                              |
| 前人方法二 |                |                                                              |
| 他的方法   |                |                                                              |

![image-20220122163833167](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220122163833167.png)

路网映射-》加剧稀疏问题

空间分区-》简单快速 映射为统一小格子



#### 主要优势：

#### 1：不利用任何个人隐私数据，`使用通用人群数据`

#### 2：

![image-20220122161741634](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220122161741634.png)



对汽车目的地进行预测

### 精读部分：模型组成

![](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220122183054503.png)



![image-20220122155243811](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220122155243811.png)

### 精读部分：参考资料与总结

![image-20220122163408465](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220122163408465.png)

![image-20220122163340824](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220122163340824.png)

## **序号7：Prediction-based underutilized and destination host selection approaches for energy-efficient dynamic VM consolidation in data centers.**

### 笑死我了，这是一篇关于虚拟机的文章



## 序号8： DNEAT: A novel dynamic node-edge attention network for  origin-destination demand prediction







这个是需求预测



![显著提高Transformer在小规模数据集的性能，特伦托大学联合腾讯提出新损失函数！](https://pica.zhimg.com/v2-32a40b8bc728fc509f63aea95a090bb3_1440w.jpg?source=172ae18b)

图神经网络精读：显著提高Transformer在小规模数据集的性能，特伦托大学联合腾讯提出新损失函数！

比如 娱乐区域  



[![机器学习社区](https://pic1.zhimg.com/v2-d5601fd765cdb4f022137d9dd82557b7_xs.jpg?source=172ae18b)](https://www.zhihu.com/people/chen-xi-63-33-5)

[机器学习社区](https://www.zhihu.com/people/chen-xi-63-33-5)

关注

52 人赞同了该文章

作者小马，来自[特伦托大学提出新损失函数，](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/aMaF3RFopTlesdhG4nxqFw)

> 欢迎关注
>
>  
>
> [@机器学习社区](https://www.zhihu.com/people/b2aa86a2a1d6f226ac4e03b5da990887)
>
>  
>
> ，专注学术论文、机器学习、人工智能、Python技巧

本文分享 NeurIPS 2021 论文**Efﬁcient Training of Visual Transformers with Small-Size Datasets**，由特伦托大学&腾讯联合提出新的损失函数，复现简单，可显著提高Transformer在小规模数据集上的性能，最高涨45%的精度！**喜欢本文，点赞、收藏、关注。**

详细信息如下：

![img](https://pic2.zhimg.com/80/v2-8ff7d81beb67596523e4249be054c121_720w.jpg)

- 论文链接：[https://arxiv.org/abs/2106.03746](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2106.03746)
- 项目链接：未开源

## **导言**



19年之前 -20年 21年

视觉Transformer(VT) 正在成为卷积网络 (CNN) 结构范式的一种替代方案。与CNN不同，VT可以捕获图像元素之间的全局关系，并且它具有更强的表示能力。然而，由于缺乏卷积的归纳偏置，这些VT模型比普通CNN更需要数据，因为VT需要从大量的数据中学习这类信息。

在本文中，作者对不同的VT进行了实验分析，比较了它们在小训练集中的鲁棒性，结果表明，**尽管在ImageNet上训练时具有相当的精度，但它们在较小数据集上的性能会有很大的不同。**因此，作者提出了一种自监督的任务，该任务可以从图像中提取其他信息，而计算开销却可以忽略不计。

此任务鼓励VT学习图像中的空间关系，并在训练数据不足时使VT训练更加鲁棒。本文的自监督任务可以与监督任务联合使用，并且它不依赖于特定的网络结构，因此它可以很容易地插入现有的VT中。基于不同的VT结构和数据集进行广泛的评估，作者证明了本文的方法可以提高 VT的准确率。

**技术交流群**

建了深度学习交流群！想要进交流群、获取资料的同学，可以直接加微信号：**mlc2060**。加的时候备注一下：**研究方向 +学校/公司+知乎**，即可。然后就可以拉你进群了。

**强烈推荐大家关注**[机器学习社区](https://www.zhihu.com/people/chen-xi-63-33-5)**知乎账号和**[机器学习社区](https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/moRNkCaBDtYZgXwaZDXBwA)**微信公众号，可以快速了解到最新优质文章。**

https://github.com/lucidrains/vit-pytorch#vision-transformer---pytorch

https://github.com/google-research/vision_transformer



![image-20220209194615464](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220209194615464.png)

## **01 Motivation**

视觉Transformers(VTs)是计算机视觉中最近兴起的一种结构，可以替代标准的卷积神经网络(CNN)，并且已经被应用于许多任务，如图像分类，目标检测，分割，跟踪和图像生成。视觉Transformer中的开创性工作是ViT，它使用非重叠的patch来分割图像，每个patch进行线性投影，从而获得“token”。之后，所有的token都由一系列的多头注意和前馈层处理，类似于NLP Transformers中token的处理方式。

![image-20220209192408336](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220209192408336.png)

**当对中等规模的数据集（例如ImageNet）进行训练时，此类模型所产生的适度精度要比同等规模的ResNet低几个百分点**。 **这种看似令人沮丧的结果可能是预期的：transformer缺乏CNN固有的一些感应偏差，例如平移不变性和局部性，因此在训练不足的数据量时不能很好地概括。**

VTs的明显优势是网络可以使用注意力层来模拟token之间的全局关系，这是相对于CNN的主要区别。然而，基于视觉信息的局部性、平移不变性和层次性，VTs表征能力的提高是以缺乏CNN中的归纳偏置为代价的。因此，VT需要大量的数据来进行训练。例如**，ViT使用JFT-300M进行训练，JFT-300M是由3.03亿张高分辨率图像组成的巨型数据集。当只在ImageNet-1K(大约130万样本)上训练时，ViT的性能比具有类似参数量的Resnet差。这可能是由于ViT需要使用比CNN更多的样本来学习视觉数据的一些局部属性，而CNN则将这些性质嵌入到了它的结构设计中。**

但是，如果在更大的数据集上训练模型（14M-300M图像），则图片会发生变化。 我们发现大规模的训练胜过归纳偏见。ViT经过足够的预培训并转移到数据点较少的任务时，可以获得出色的结果。当在公共ImageNet-21k数据集或内部JFT-300M数据集上进行预训练时，ViT在多个图像识别基准上达到或超越了最新水平。特别是，最佳模型在ImageNet上达到88.55％的精度，在ImageNet-ReaL上达到90.72％的精度，在CIFAR-100上达到94.55％的精度，在19个任务的VTAB上达到77.63％的精度。





为了缓解这个问题，**第二代的VT结构被提出，**这些网络通常是将**卷积层与注意层混合在一起，从而为VT提供了局部归纳偏置**。这些混合结构同时具备两种范例的优势: 注意层对全局依赖关系进行建模，而卷积操作可以强调图像内容的局部特征。大多数工作中的实验结果表明，这种第二代的VTs可以在ImageNet上进行训练，其性能优于此数据集上类似大小的ResNet。**然而，在中小型数据集上进行训练时，这些网络的结果仍不清楚。**







![image-20220209192129936](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220209192129936.png)



![image-20220209193954081](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220209193954081.png)

当前的主流做法

![image-20220209192211513](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220209192211513.png)

![image-20220209192457673](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220209192457673.png)

在本文中，作者通过在中小型数据集上，从头开始训练它们或对它们进行微调来相互比较不同第二代VT结构的区别。实验结果表明，**尽管它们的ImageNet性能基本上彼此相当，但它们在较小数据集上的分类精度却有很大的不同。此外，作者提出使用其他自监督的任务和相应的损失函数，以加快在小型训练集或更少epoch数约束下的训练。具体而言，该任务是学习输出token嵌入之间的空间关系。**

由于这个任务是自我监督的，因此该任务的**密集相对定位损失函数** () 不需要额外的标注，并且可以将其与标准交叉熵联合使用，作为VT训练的正则化。非常简单且容易复现，它可以在很大程度上提高了VTs的准确性，尤其是当VT在小数据集上从头开始训练，或者在相对于预训练ImageNet数据集具有较大域偏移的数据集上进行微调时。在实验中，基于不同的训练场景、不同的训练数据量和三种不同的VTs，对baseline的结果都有提升，有时会提高数十个点 (最多45个点) 的准确率。



## **02 方法**

## **2.1. Preliminaries**

在本文中，作者重点关注第二代VT，它们是混合了自注意力层和卷积运算的混合结构。**这些网络将图像作为输入**，**该图像首先被分割成K×K个patch，然后用线性投影将patch投到样嵌入空间中，得到一组K × K个的输入token。**在VT中，自注意力层和卷积结构能够对这些token进行全局和局部信息的建模。其中使用步长大于1的卷积或池化操作，可以降低初始K × K的token特征的分辨率，从而模拟CNN的层次结构。

![img](https://pic3.zhimg.com/80/v2-115f562f97d0f4175adf20f5f4cc2166_720w.jpg)

对于用于分类的特征，有的方法采用了额外的class token，另外也有一些方法采用了将所有grid的特征进行平均池化来获得整张图片的表示，从而来进行分类。最后，在这些用于分类的特征上进行MLP来获得目标类集合的后验分布，并使用交叉熵损失函数来进行训练VT。

## **2.2. Dense Relative Localization task**

本文提出的正则化损失的目标是鼓励VT在不使用额外的人工标注的情况下学习空间信息。作**者通过对每个图像的多个嵌入对进行密集采样并要求网络预测它们的相对位置来实现空间信息的学习。具体实现上，给定图像，将VT最后输出的grid特征表示为，其中，是嵌入空间的维数。**对于每个，作者**随机采样多对嵌入，并且对于每个采样对，计算2D归一化平移偏移量 ，计算方式如下:**

![img](https://pic4.zhimg.com/80/v2-13bb1fcd84520fc94f6e99dd89745e0b_720w.jpg)

![img](https://pic3.zhimg.com/80/v2-f46f60871aacd018a72cc245eeaede86_720w.jpg)

将选定的嵌入向量和进行concat，然后输入到一个MLP中，该MLP具有两个隐藏层和两个输出神经元（如上图所示），用来预测网格上位置 ， 和位置，之间的相对距离，即

。给定一个Batch 的n个图像，本文提出的密集相对定位损失（dense relative localization loss）为：

![img](https://pic3.zhimg.com/80/v2-aa012be2c290f34146ec95f6aeaf2ad6_720w.jpg)

被添加到每个原始VT 的标准交叉熵损失（）中。最后总的损失为: 。在T2T和CvT的所有实验中使用 λ = 0.1，在Swin中使用 λ = 0.5。

## **2.3. Loss variants**

除了最简单的dense relative localization loss，作者还提出该损失函数的一些变体。

**变体1：**

上面的损失基于横向和纵向相对距离的绝对值，变体1中还考虑正负的方向，如下所示：

![img](https://pic3.zhimg.com/80/v2-2225812cfc58097404845c4561ebefee_720w.jpg)

用代替原始公式中的，其他部分保持不变。变体1 的损失函数记为。

**变体2：**

在变体2中，作者将回归任务转换成了分类任务，并将L1损失修改为交叉熵损失。计算上，目标的偏移计算如下：

![img](https://pic4.zhimg.com/80/v2-c01f8b3e61e569332edc77fae33eec77_720w.jpg)

然后，我们将，，中的个离散元素与相应的类相关联。此外还需要将MLP中两个输出神经元替换为两组输出神经元，每组神经元输出代表个类。Softmax分别应用于每组个神经元，的输出由上的两个后验分布组成:。该变体的损失函数为：

![img](https://pic3.zhimg.com/80/v2-230eaed5ed18488721424ec59488231a_720w.jpg)

其中表示的第个元素

**变体3：**

上述公式中的交叉熵损失，将看做是一个无序的“类别”集合。这意味着 (和) 中的预测误差与相对于ground truth (和) 是 “距离” 无关的。为了缓解这个问题，作者提出的第三种变体，在和上施加了高斯先验，并最小化的期望值与ground truth (分别为和) 之间的归一化平方距离。在实现上，令均值,方差，损失函数可以表示为：

![img](https://pic2.zhimg.com/80/v2-79c88f5a1aae6697060147ed7e89ab11_720w.jpg)

其中，和用于方差正则化。

**变体4：**

最后一个变体是基于 “非常密集” 的定位损失，即针对VT的每个Transformer块计算。具体地说，设是由VT的第l个块输出的的token嵌入，L为Transformer块的总数。然后，新的损失函数为:

![img](https://pic1.zhimg.com/80/v2-4c530d4a6c87957277c839081bf04b30_720w.jpg)

其中，和分别是在第个块中随机采样对计算的目标偏移量和预测偏移量。不同的Transformer块，采用不同的MLP来预测。



## **03 实验**

![img](https://pic4.zhimg.com/80/v2-858aeedda145aceb4440322fdc11d18f_720w.jpg)

作者在不同的数据集上进行了实验，上表为本文进行实验数据集的具体信息。

## **3.1 Ablation study**

![img](https://pic1.zhimg.com/80/v2-e8fa1b6554f38bc59c13d13a7a7cc474_720w.jpg)

作者在ImageNet-100上对不同损失函数变体进行了实验，可以看出，除了之外，其他损失函数都能提高性能。

![img](https://pic3.zhimg.com/80/v2-cc7de5cceef64e19dc17584f69afd6aa_720w.jpg)

上表为CIFAR-10上的结果，m为采样数量，可以看出，m为64是效果最好。

## **3.2 Training from scratch**

![img](https://pic3.zhimg.com/80/v2-a89ec419578eefd65545f79ece6eea42_720w.jpg)

上表显示了不同VT模型，不同epoch数下的实验结果，可以看出本文的方法在不同模型和不同epoch数下，都能提升模型性能。

![img](https://pic2.zhimg.com/80/v2-a4837c17c29e8a814510083d00858d69_720w.jpg)

上表展示了不同模型在不同数据集上的结果，可以看出，加上本文方法之后，性能都有提升，最高提升了45个点。

## **3.3 Fine-tuning**

![img](https://pic4.zhimg.com/80/v2-7dcdb62841818c82774c23653db7292f_720w.jpg)

上表展示了ImageNet上预训练的模型，在不同数据集上进行微调的结果，可以看出，本文的方法依旧能够提升模型性能。



**04 总结**

在本文中，作者对不同的VT进行了实验分析，结果表明，当用中小型数据集从头开始训练时，这些模型的性能差别很大。为了缓解这一问题，作者提出了一项自监督任务，用来进行VT的训练。该定位任务是对最后层的token嵌入对进行密集地随机采样，并且它鼓励VT学习空间信息。

在实验中，作者使用了11个数据集、不同的训练设置和3个VT模型，本文的密集定位损失都能够提高相应的baseline精度。这表明本文提出的任务和损失函数，可以提高VT的性能，特别是在数据/训练时间有限的情况中。此外，它还为研究其他形式的自监督/多任务学习铺平了道路，可以帮助VT更好的训练，而不需要使用大量标注数据集。



1/3 Uniformer论文





### 相关信息：

## **论文标题：UNIFORMER: UNIFIED TRANSFORMER FOR EFFICIENT SPATIOTEMPORAL REPRESENTATION LEARNING**

**year：2022

**Publish :Published as a conference paper at ICLR 2022**

中科院深圳先进技术研究院、商汤和上海 AI Lab 的研究者合作完成的 UniFormer




**Cited:35**

**Code：无**

**Data：**

- 论文 V1 地址：https://arxiv.org/pdf/2201.04676.pdf
- 论文 V2 地址：https://arxiv.org/pdf/2201.09450.pdf
- 项目地址：https://github.com/Sense-X/UniFormer
- 代码 https://github.com/Sense-X/UniFormer
- demo   https://huggingface.co/spaces/Sense-X/uniformer_image_demo

### 数据预处理：UserID 纬度 经度 时间戳

## 当前问题：

现有的两大主流模型 CNN 和 ViT

卷积：只在局部小邻域聚合上下文，天然地避免了冗余的全局计算，但受限的感受野难以建模全局依赖。

ViT： 在浅层编码局部特征十分低效,+被关注的 token 集中在 3x3 邻域中（红色越深关注越多）。





而自注意力通过比较全局相似度，自然将长距离目标关联，但如下可视化可以发现

![img](https://inews.gtimg.com/newsapp_bt/0/14474461011/641)

![img](https://inews.gtimg.com/newsapp_bt/0/14474461080/641)



旨在**以 Transformer 的风格，有机地统一卷积和自注意力，发挥二者的优势，同时解决局部冗余和全局依赖两大问题.

### 核心IDEA： 多层CNN+tramsfomer









T是属于的只有视频才有的时间输入

![image-20220211191934847](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220211191934847.png)

![image-20220211192338198](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220211192338198.png)

模型整体框架如上所示，借鉴了 CNN 的层次化设计，每层包含多个 Transformer 风格的 UniFormer block。



每个 UniFormer block 主要由三部分组成，DPE、多头关系聚合器 MHRA 以及 Transformer 必备的前馈层 FFN，

DPE 主要是捕捉图像临近关系

最关键的为多头关系聚合器：

![image-20220211193621474](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220211193621474.png)



![image-20220211194818664](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220211194818664.png)



每个 UniFormer block 主要由三部分组成，动态位置编码 DPE、多头关系聚合器 MHRA 以及 Transformer 必备的前馈层 FFN，

最关键的为多头关系聚合器：

![image-20220211193621474](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220211193621474.png)

正如前面所提到：CNN与ViTs分别聚焦于解决局部冗余与全局依赖，导致了次优性能、不必要的计算冗余。为解决上述问题，**我们引入了一种广义相关性聚合(Relation Aggregator, RA)，它将卷积与自注意力统一为token相关学习。通过在浅层与深层设计局部与全局token affinity，它能够取得更高效&有效的表达学习能力**。具体来说，MHRA以多头方式探索token相关性：



对于输入，我们首先将其reshape为token序列。表示RA的第n个头，表示可学习参数矩阵用于N个头聚合。每个RA包含token上下文编码与token亲和学习。我们通过线性变换将原始token编码为上下文token，然后RA可以通过token相关性矩阵An对token进行上下文信息聚合。

Local MHRA

![image-20220211193721848](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220211193721848.png)

<img src="C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220211193523324.png" alt="image-20220211193523324" style="zoom:25%;" />



与多头注意力相似，我们将关系聚合器设计为多头风格，每个头单独处理一组 channel 的信息。每组

他们在浅层设计了局部相关性参数矩阵。具体来说，给定输入token ，局部RA在小范围内进行token间相关性计算：

其特点为 只描述 相对位置信息，不描述数寄依赖性



基于前面的可视化观察，研究者认为在网络的浅层，token affinity 应该仅关注局部邻域上下文，这与卷积的设计不谋而合。因此，他们将局部关系聚合![Image](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9nItLPCleibr8Toql9NE6O9S5D5U3S8rFSaMKXKTSoWm9Ds24rqmRdnWORAUM2VXSrU0xib5GvBdUQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)设计为可学的参数矩阵：

![image-20220211193900618](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220211193900618.png)

![image-20220211193603024](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220211193603024.png)

其中![Image](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9nItLPCleibr8Toql9NE6O9Y2F9cHPfIg89pZqNbBOEOWMs1f2F6zJcG1nD2omVhT6eDXqChNeh7A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)为 token，![Image](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9nItLPCleibr8Toql9NE6O9OqEQibZSc8txRWxiba75stHySjGbibal5QNytrCL9NqJYakickshOfeibXA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)为局部邻域 ![Image](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9nItLPCleibr8Toql9NE6O9fvxvJGE7Z6xtT0YS72doicicFWUotD5QQpGu7ibAMWV0PjXTRibzI8sibJg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)任一 token，![Image](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9nItLPCleibr8Toql9NE6O91x2nf1ZWjtXP7TRKL2B5HxicP5NuUaMOiagdGBxY5FfhErndKrMOwZOw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)为可学参数矩阵， ![Image](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9nItLPCleibr8Toql9NE6O9DmjEqVfd8N4RTCHicSQRYORtIaScJxafx7jvwGGjiaLgbw8O805QfMKA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)为二者相对位置，表明 token affinity 的值只与相对位置有关。这样一来，local UniFormer block 实际与 MobileNet block [3] 的风格相似，都是 PWConv-DWConv-PWConv（见原论文解析)，**不同的是研究者引入额外的位置编码以前前馈层，这种特别的结合形式有效地增强了 token 的特征表达**。

![image-20220211193701696](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220211193701696.png)

### Global MHRA

在网络的深层，研究者需要对整个特征空间建立长时关系，这与自注意力的思想一致，因此通过比较全局上下文相似度建立 token affinity：

### 

在深层，长距离相关性探索非常重要，它具有与自注意力相似的思想。因此，我们从全局视角设计了token相关性矩阵：



![Image](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9nItLPCleibr8Toql9NE6O9iaOpasxeQF7L0Micv12t6QGuK1BFt9rPoEuM4Iu0jz7Yyv5bzibMNXhIA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

*global MHRA*



其中![Image](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9nItLPCleibr8Toql9NE6O9XSPMvPRMEv9zQic3ozceTHicelcgQqwZ0MxTqiac09uVibMrge04DdMtBA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)为不同的线性变换。先前的视频 transformer 往往采用时空分离的注意力机制 [4]，以减少视频输入带来的过量点积运算，但这种分离的操作无疑割裂了 token 的时空关联。相反，UniFormer 在网络的浅层采用 local MHRA，节省了冗余计算量，使得网络在深层可以轻松使用联合时空注意力，从而可以得到更具辨别性的视频特征表达。再者，与以往 ViT 中使用绝对位置编码不同，这里采用卷积风格的动态位置编码，使得网络可以克服排列不变形（permutation-invariance)的同时，对不同长度的输入更友好。



流行的 ViT 往往采用绝对或者相对位置编码 [5]，但绝对位置编码在面对更大分辨率的输入时，需要进行线性插值以及额外的参数微调，而相对位置编码对自注意力的形式进行了修改。为了适配不同分辨率输入的需要，研究者采用了最近流行的卷积位置编码 [6] 设计动态位置编码:



![Image](https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9nItLPCleibr8Toql9NE6O9U5f0DibZTagXamtZiau7dOKV6ia2uPaDp4TxZFMRu7P3oj2icIxJPPemWg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

*DPE*



其中 DWConv 为零填充的的深度可分离卷积。一方面，卷积对任何输入形式都很友好，也很容易拓展到空间维度统一编码时空位置信息。另一方面，深度可分离卷积十分轻量，额外的零填充可以帮助每个 token 确定自己的绝对位置。

![image-20220212202838968](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220212202838968.png)

![image-20220212202813512](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220212202813512.png)

![image-20220212202730834](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220212202730834.png)



### 精读部分：模型组成

### 精读部分：参考资料与总结





## 序号12：Short-term origin-destination demand prediction in urban rail transit systems: A channel-wise attentive split-convolutional neural network method

## 序号：读论文的模板



### 相关信息：

**论文标题：Short-term origin-destination demand prediction in urban rail transit systems: A channel-wise attentive split-convolutional neural network method**

**year：2021（今年的比较新）

**Publish :**Transportation Research Part C** SCI, IF=6.077, JCR: Q1, 中科院一区 大佬论文

**Cited:4

**Code： 

**Data：无*

![image-20220126153336220](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220126153336220.png)

### 数据预处理：UserID 纬度 经度 时间戳

### 核心IDEA：

主要解决问题：短期OD流预测

解决的三个痛点：

![image-20220126154144472](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220126154144472.png)

1)数据可用性：预测过程中无法获得实时OD流；

2)数据维度：OD流的维数远高于交通网络的基数； 

3)数据稀疏性 sparsity：城市轨道交通OD流具有时空稀疏性。 

解决方法 引入了进站/出战门控机制来解决数据可用性问题。为了解决数据的维数和数据稀疏性问题

提出的方法：基于通道的**注意力****分离卷积**神经网络(CAS-CNN)。

模型如基于通道的注意机制和分离的CNN

其他创新点： 掩码损失函数。模型的可解释性。

**创新点：**

（1）详细总结了轨道交通OD预测的特点以及与其他交通预测任务的比较。总结了**轨道交通短期OD预测**存在的问题。

（2）考虑到历史OD流量信息和实时进站/出站信息之间的内在相关性，提出了一种汇聚**历史OD流量信息**和**实时进站/出站信息的**门控机制

（3）引入分离的CNN模型，将**稀疏的OD流信息**转化为**密集的有用特征**。(这是分离CNN首次在短期OD预测中引入)

（4）提出了一种基于**OD吸引度(ODAD)指标的掩码损失函数**，用于处理较小或为零的OD流。

**CAS-CNN模型在**北京地铁的两个大规模真实数据集上进行测试

### 精读部分：模型组成

**看到作者有一篇博客讲这个哈哈哈哈，我直接白嫖了**

**[月，日，周，每日时间，是否是假期，，]**

**3.1 Problem definition**

本研究的目的是利用历史信息对下一时段的OD矩阵进行预测。在本研究中，时间间隔被定义为30分钟。OD矩阵M和进站/出站N可以从城市轨道交通中的智能卡数据中提取，并可以根据以下等式定义。值得注意的是，每**个时间间隔的OD流量取决于乘客进入车站的时间间隔，**因为每个乘客的离开时间可能不同。根据相应的进站、进站时间、出站和出站时间提取进站/出站序列。

![image-20220126162420907](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220126162420907.png)



![img](https://pic1.zhimg.com/80/v2-70b65e780a7687ad147c770fda7b18e0_720w.jpg)

![img](https://pic4.zhimg.com/80/v2-b20d9962e324938f71e1065e59b82fb3_720w.jpg)

关于短时OD预测，以往的研究一般使用最近几个时间间隔的OD矩阵作为模型输入来预测后续时间间隔的OD矩阵。然而，由于出行持续时间的限制，无法获得实时的OD矩阵。因此，这些研究不能应用于实时操作。同样，在轨道交通的实时运营中，无法获得实时的OD矩阵。然而，实时进站/出站是可用的。因此，本研究试图利用前几天的OD矩阵，以及当天的进站/出站，来预测短期OD矩阵。方程式如下：

![img](https://pic4.zhimg.com/80/v2-25644aa4cd476269a3e745993378307b_720w.jpg)

其中是在d天的时间间隔t中的OD矩阵。**输入之一是在过去几天d-x的相同时间间隔t中的OD矩阵。另一个输入是同一天d的最后几个时间间隔t-y期间的进站/出站序列。**

由于无法获得实时OD矩阵，我们创新性地设计了一种以实时流入为输入的进站/出站门控机制，以提供实时信息。

3.2 Origin–destination **attraction degree** (ODAD) level （吸引能力）

为了表征不同流量的OD流，我们引入了一个新的指标ODAD。它被定义为一个较长周期内特定时间间隔内的平均OD流量，如公式所示。





![image-20220126160649069](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220126160649069.png)



![image-20220126161606958](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220126161606958.png)

![image-20220126160758721](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220126160758721.png)

![img](https://pic2.zhimg.com/80/v2-555c58d7d4b49e65d77bcc3d11ee3f6d_720w.jpg)

其中是在**n天期间从站i到站j的平均OD流量。这是一个随时间变化的动态指标**。对于特定的OD对，值可能在清晨较低，而在高峰时段较高。这也是用来避免随机性的平均指标。





![image-20220126160847252](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220126160847252.png)

为了处理具有不同吸引程度的OD对，我**们将所有OD对按照ODAD值分为五个等级，如表所示，不同ODAD等级下OD数量的变化如图所示，时间上，低等级和最低等级的OD对占大多数**。

**在空间上，OD流只发生在特定区域。这些较小的值对模型性能有负面影响，因为缺乏规律性增加了预测的难度。因此，处理这些小值或零值很有挑战性**

。为了解决这一问题，我们创新性地根据3.7节中“低”的ODAD水平引入了掩码损失函数，从而减少了小OD流量或零OD流量对预测精度的影响。这项研究中使用的“低”ODAD水平是固定的，不会随着时间的推移而改变。

![img](https://pic4.zhimg.com/80/v2-bed4c15b153e1d5bd3edca04f058bd8f_720w.jpg)



![img](https://pic2.zhimg.com/80/v2-215d282324462189654447cfd02189f9_720w.jpg)

**3.3 Model development**

这篇文章提出了基于分离式CNN、通道注意力和进站/出站门控机制的预测框架(简称CAS-CNN，如下图)来进行城市轨道交通OD的短期预测。CAS-CNN包括历史数据和实时数据两个分支。

![img](https://pic1.zhimg.com/80/v2-eafa7b99c83bf9cdef46771cab11dd80_720w.jpg)

在历史数据的分支(简称主干)中，**首次引入分离的CNN来捕捉不同感知场的时空相关性，并从稀疏的OD流中产生密集的信息。利用通道注意力度对输入进行加权，并从OD矩阵中提取不同的高层特征。据我们所知，这是首次将分离的CNN应用于城市轨道交通OD预测。**



![image-20220126160905363](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220126160905363.png)

在空间上，如图4所示，只有一些特定的区域存在OD流。**因此，在平坦区域中，较小的核足以捕获其空间特征。然而，在峰值区域，较大的内核更适合，因为它可以使用更大的感知场捕获更多信息。**在这种情况下，一些重要信息不能轻易省略。

在实时信息的分支中，我们使用实时进站/出站作为输入来提取重要信息。为了融合这两个数据源，设计了一种巧妙的进站/出站门控机制，通过考虑历史OD流量信息和实时进站/出站信息之间的内在相关性来聚合它们。

为了解决OD流量小且为零的问题，我们还引入了一种基于低ODAD水平的掩码损失函数。

在接下来的几节中，我们将详细介绍分离CNN、通道注意力、进站/出站门控机制以及掩码损失函数。

**3.4 Split CNN**

现有的研究一般使用一个相同大小的核来提取特征。在这种情况下，为了提高训练性能，通常的方法是增加网络深度(层数)。然而，层数的增加有多个不良影响，如过拟合、梯度消失、梯度爆炸等。虽然残差网络被提出解决这些问题，但它也增加了网络的复杂性和训练时间等计算资源。

在GoogLeNet的启发下，本研究首次引入分离CNN模型来解决短期OD预测任务。据我们所知，这是首次将分离的CNN应用于城市轨道交通的短期OD预测。我们选择用不同的内核来扩展网络，而不是加深网络，因为这可以有效地增加网络的适应性

如上所述，城市轨道交通短期OD预测的问题之一是数据稀疏。由于在两个方面存在严重的数据稀疏问题，分离式架构非常适合于轨道交通的OD矩阵。

从时间上看，**ODAD水平“最低”的OD流(即，零OD流)全天都超过40%。通过设计分离结构，可以从相对稀疏的矩阵中产生密集的数据，并且可以通过不同大小的核来提取更多的信息。它不仅提高了神经网络的性能，而且保证了训练效率**

在空间上，只有某些特定区域存在OD流。因此，在平坦区域，较小的核足以捕捉其空间特征。然而，在峰值区域，更大的核更合适，因为它可以使用更大的感知场来捕捉更多的信息。在这种情况下，一些重要信息不能轻易遗漏。

为此，我们引入了分离的CNN用于城市轨道交通OD预测。第i层的第j特征图中位置(x，y)处的值v可以如下计算

![img](https://pic3.zhimg.com/80/v2-1ca569ec599e7944095bb35fbdf6285e_720w.jpg)

**3.5 Channel-wise attention**

人-视觉注意机制是人类视觉的一种脑信号处理机制。通过快速扫描全局图像，人类视觉获得需要关注的目标区域。然后，更多的注意力资源被投入到这一领域，以获得关于目标的更详细的信息。其他无用的信息同时被隐藏。这是一种被人类用来在有限的注意力资源下从大量信息中快速选择高价值信息的机制。人类视觉注意机制显著提高了视觉信息处理的效率和准确性。

在人类视觉注意的驱动下，人们提出了多种注意机制，如Transformer中的自我注意和位置注意、残余注意、多层注意和空间注意。通道注意机制最早是由Chen等人提出的。它被用来权衡不同的高层特征，并可在多个方面应用于OD预测。

一方面，在轨道交通OD预测领域，缺乏实时的OD矩阵。因此，我们使用过去几天相同时间间隔内的OD矩阵作为模型输入之一。然而，**有些OD矩阵与输出高度相关。其中一些与产出的关联度较低。人们理所当然地认为，通道方面的关注可以用来权衡不同的OD输入。**

![image-20220301205607684](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220301205607684.png)

另一方面，分离CNN的输出代表了从输入中提取的高层特征。重要的是，自适应地更多地关注一些关键特性，以提高模型性能。因此，文章创新性地将通道注意机制应用到**分离的CNN的输出中**，并将它们加在一起。下图显示了通道注意力的详细信息。因此，输出可以表示如下。

![img](https://pic2.zhimg.com/80/v2-a9ad54d4e5a757e5b6ad3c2cc7d6a4fd_720w.jpg)

![img](https://pic1.zhimg.com/80/v2-5357280048d4fb4df08e5b9991f4d950_720w.jpg)

**3.6 Inflow/outflow-gated mechanism**

如上所述，在城市轨道交通中，实时OD矩阵是不可用的。如何结合实时信息进行OD预测是非常重要的。进站/出站与OD流量之间存在很强的相关性。

在这种关系的推动下，文章首次引入了进站/出站门控机制来有效地控制干线输出，并融合了进站/出站和OD矩阵信息，如下图所示。**进站/出站经过1×1卷积层。它们的输出被相乘，然后被注意力参数向量加权。加权的流入特征加上模型主干按行的输出，然后进行1×1卷积，得到最终的预测结果**。

![img](https://pic1.zhimg.com/80/v2-22155799c8ad71b5a8ca8318f56da9ec_720w.jpg)

![img](https://pic1.zhimg.com/80/v2-84297698897679a6cf0186ee49b39358_720w.jpg)

值得注意的是，应用1×1卷积层来获得最终输出。每个1×1卷积核可以实现跨通道的信息通信。在提取非线性特征时，1×1核可以代替完全连通层，同时降低了模型复杂度。因此，虽然这意味着简单的线性组合，但它有利于信息融合和特征提取。

**3.7 Masked loss function**

正如前面几节所讨论的，有许多小的或零的OD流会显著影响预测性能。此外，不同ODAD水平的OD流量在时间和空间上都是高度不平衡的。因此，引入**了一个掩码损失函数(M-Loss)。根据低ODAD级别构造一个掩码文件来掩码ODAD级别低于2的OD流。**

![img](https://pic3.zhimg.com/80/v2-da9ec00888cb51878910b099c97c9a9e_720w.jpg)

![img](https://pic4.zhimg.com/80/v2-1578fe066223b5d8f293bdde72d0bb67_720w.jpg)

**模型配置：**

前四周的数据用于训练和验证模型，其余的用于测试模型。验证率设置为0.1。在模型训练过程中采用了提前停止技术，避免了过拟合。根据参数调整结果，确定了时间步长、过滤器、批次大小和R(缩减)等超参数。对于进站/出站门控分支，**利用整个网络中最后五个时间步长(2.5小时)的进站/出站序列。对于第一个拆分的CNN，有一个带有16个过滤器的层**；对于第二个拆分的CNN，有一个带有一个过滤器的层。学习率为0.001，批次大小为16。在通道方向的注意中，张量缩减R被设置为2。在过去五天的相同时间间隔内使用OD矩阵。使用Xavier正态初始化器来初始化CNN的相关参数

 加入周 信息。

模型baseline: googleLeNet

### 精读部分：参考资料与总结







# 开会讲解笔记

德昊 transfromer

还是看李沐吧

聚类 根据地理位置进行聚类 



![image-20220122200610524](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220122200610524.png)



![image-20220122200505675](C:\Users\Lenovo\AppData\Roaming\Typora\typora-user-images\image-20220122200505675.png)

## 



子诚的想法 

拉力问题

分类 句子词向量

类似苹果和香蕉问题    

输出一个轨迹点n   
